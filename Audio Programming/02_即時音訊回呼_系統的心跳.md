# 即時音訊回呼：系統的心跳

## 概述

即時音訊回呼（Real-time Audio Callback）是現代音訊程式設計的核心機制，它就像系統的心跳一樣，以固定且高頻率的間隔被呼叫，負責處理音訊資料的流動。理解這個機制對於開發穩定、低延遲的音訊應用至關重要。

## 詳細說明

### 回呼模型的基本原理

現代作業系統的音訊 API（如 Windows 的 ASIO、WASAPI，macOS 的 CoreAudio，以及 Linux 的 ALSA 或 JACK）大多採用回呼（Callback）模型來處理音訊。其運作方式如下：

1. **初始化階段**：
   - 應用程式向音訊 API 註冊一個回呼函式
   - 設定音訊參數（取樣率、緩衝區大小、通道數等）
   - 啟動音訊串流

2. **運行階段**：
   - 作業系統或音訊驅動程式以固定間隔呼叫註冊的回呼函式
   - 回呼函式接收輸入緩衝區（包含新的音訊輸入）
   - 回呼函式需要填充輸出緩衝區（將被送往音訊輸出）
   - 這個過程持續進行，直到應用程式停止音訊串流

### 處理截止期限（Processing Deadline）

回呼函式必須在一個極其嚴格的時間限制內完成其工作，這個限制被稱為「處理截止期限」。這個截止期限通常等於一個緩衝區所能容納的音訊時長。

例如，在 44.1 kHz 的取樣率下：
- 緩衝區大小為 256 個樣本，則處理截止期限約為 256/44100 ≈ 5.8 毫秒
- 緩衝區大小為 1024 個樣本，則處理截止期限約為 1024/44100 ≈ 23.2 毫秒

如果回呼函式未能在截止期限內完成其工作並填滿輸出緩衝區，音效卡將沒有新的資料可以播放，導致音訊流中斷，產生被稱為「爆音」、「喀噠聲」或「音訊下溢」（Underrun/Glitch）的聽覺瑕疵。

### 執行緒模型

為了確保系統的穩定性，音訊回呼通常在一個獨立於主應用程式執行緒的高優先級即時執行緒上執行。這種執行緒分離的架構有以下優點：

1. **優先級隔離**：音訊執行緒可以獲得更高的系統優先級，減少被其他任務中斷的可能性
2. **責任分離**：UI 執行緒處理使用者互動，音訊執行緒專注於音訊處理
3. **穩定性提升**：即使 UI 執行緒暫時阻塞（例如載入檔案），音訊處理仍能繼續

然而，這種分離也帶來了執行緒間通訊的挑戰，這是後續討論中許多並行問題的根源。

## 實際範例：使用 PortAudio 實現音訊回呼

以下是使用跨平台音訊函式庫 PortAudio 實現簡單音訊回呼的範例：

```cpp
#include <iostream>
#include <cmath>
#include <portaudio.h>

// 定義常數
const int SAMPLE_RATE = 44100;
const int FRAMES_PER_BUFFER = 256;
const int NUM_CHANNELS = 2;
const float FREQUENCY = 440.0f;  // A4 音高

// 回呼函式的狀態資料結構
typedef struct {
    float phase;            // 正弦波的相位
    float phaseIncrement;   // 每個樣本的相位增量
} CallbackData;

// 音訊回呼函式
static int audioCallback(
    const void *inputBuffer,
    void *outputBuffer,
    unsigned long framesPerBuffer,
    const PaStreamCallbackTimeInfo *timeInfo,
    PaStreamCallbackFlags statusFlags,
    void *userData)
{
    // 轉換緩衝區指標類型
    float *output = (float*)outputBuffer;
    CallbackData *data = (CallbackData*)userData;
    
    // 輸入緩衝區在此範例中未使用
    (void)inputBuffer;
    (void)timeInfo;
    (void)statusFlags;
    
    // 生成正弦波並填充輸出緩衝區
    for (unsigned long i = 0; i < framesPerBuffer; i++) {
        // 計算當前樣本值
        float sample = sinf(data->phase);
        
        // 立體聲輸出 (左右聲道)
        *output++ = sample;  // 左聲道
        *output++ = sample;  // 右聲道
        
        // 更新相位
        data->phase += data->phaseIncrement;
        
        // 保持相位在 0 到 2π 之間
        if (data->phase >= 2.0f * M_PI) {
            data->phase -= 2.0f * M_PI;
        }
    }
    
    return paContinue;  // 繼續串流
}

int main() {
    PaError err;
    PaStream *stream;
    CallbackData data;
    
    // 初始化 PortAudio
    err = Pa_Initialize();
    if (err != paNoError) {
        std::cerr << "PortAudio 初始化錯誤: " << Pa_GetErrorText(err) << std::endl;
        return 1;
    }
    
    // 初始化回呼資料
    data.phase = 0.0f;
    data.phaseIncrement = 2.0f * M_PI * FREQUENCY / SAMPLE_RATE;
    
    // 開啟音訊串流
    err = Pa_OpenDefaultStream(
        &stream,
        0,                  // 無輸入通道
        NUM_CHANNELS,       // 立體聲輸出
        paFloat32,          // 32位元浮點樣本
        SAMPLE_RATE,
        FRAMES_PER_BUFFER,
        audioCallback,
        &data);
    
    if (err != paNoError) {
        std::cerr << "開啟串流錯誤: " << Pa_GetErrorText(err) << std::endl;
        Pa_Terminate();
        return 1;
    }
    
    // 啟動串流
    err = Pa_StartStream(stream);
    if (err != paNoError) {
        std::cerr << "啟動串流錯誤: " << Pa_GetErrorText(err) << std::endl;
        Pa_CloseStream(stream);
        Pa_Terminate();
        return 1;
    }
    
    // 播放 5 秒
    std::cout << "播放 A4 音高 (440 Hz) 5 秒..." << std::endl;
    Pa_Sleep(5000);
    
    // 停止並關閉串流
    err = Pa_StopStream(stream);
    if (err != paNoError) {
        std::cerr << "停止串流錯誤: " << Pa_GetErrorText(err) << std::endl;
    }
    
    err = Pa_CloseStream(stream);
    if (err != paNoError) {
        std::cerr << "關閉串流錯誤: " << Pa_GetErrorText(err) << std::endl;
    }
    
    // 終止 PortAudio
    Pa_Terminate();
    
    return 0;
}
```

這個範例展示了一個典型的音訊回呼實現：
1. 初始化音訊系統並設定參數
2. 定義一個回呼函式，負責生成音訊資料
3. 開啟並啟動音訊串流，此時系統開始定期呼叫回呼函式
4. 主程式可以繼續執行其他任務，音訊處理在背景進行
5. 最後，停止並清理音訊資源

### 回呼函式的關鍵特性

在上面的範例中，`audioCallback` 函式展示了音訊回呼的幾個關鍵特性：

1. **即時性**：函式必須快速執行，不能超過處理截止期限
2. **無阻塞**：函式不應執行任何可能阻塞的操作
3. **確定性**：函式的執行時間應該是可預測的
4. **狀態管理**：通過 `userData` 參數維護狀態，而非使用全域變數

## 實際應用

理解音訊回呼機制對於以下應用至關重要：

1. **數位音訊工作站（DAW）**：處理多軌音訊和虛擬樂器
2. **音訊外掛程式**：VST、AU、AAX 等格式的效果器和樂器
3. **遊戲音效引擎**：即時生成和處理遊戲音效
4. **音訊串流應用**：網路廣播、VoIP 等

## 最佳實踐

1. **保持回呼函式簡潔**：
   - 只執行必要的音訊處理
   - 避免複雜的演算法或大量計算

2. **預先分配資源**：
   - 在回呼外預先分配所有需要的記憶體
   - 避免在回呼中進行動態記憶體配置

3. **避免阻塞操作**：
   - 不要在回呼中執行 I/O 操作
   - 不要在回呼中獲取鎖或等待其他執行緒

4. **測量和監控效能**：
   - 追蹤回呼函式的執行時間
   - 確保它始終低於處理截止期限

## 參考資料

1. Real-time audio programming 101: time waits for nothing - Ross Bencina: [http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing](http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing)

2. PortAudio - Cross-platform Audio API: [http://www.portaudio.com/](http://www.portaudio.com/)

3. Audio I/O: Buffering, Latency, and Throughput - MATLAB & Simulink: [https://la.mathworks.com/help/audio/gs/audio-io-buffering-latency-and-throughput.html](https://la.mathworks.com/help/audio/gs/audio-io-buffering-latency-and-throughput.html)

4. JUCE Audio Callback Documentation: [https://docs.juce.com/master/tutorial_audio_processor_graph.html](https://docs.juce.com/master/tutorial_audio_processor_graph.html)